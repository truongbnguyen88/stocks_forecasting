{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/truongnguyen/miniforge3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "import xgboost as xgb\n",
    "\n",
    "import sys, os, yaml, ta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import yfinance as yf\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from stock_forecast_module import *\n",
    "\n",
    "import requests, zipfile, io\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gdelt_export_for_date(date):\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    url = f\"http://data.gdeltproject.org/events/{date_str}.export.CSV.zip\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"No data for {date_str}\")\n",
    "            return None\n",
    "        \n",
    "        z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "        csv_name = z.namelist()[0]\n",
    "        df = pd.read_csv(z.open(csv_name), sep='\\t', header=None, low_memory=False)\n",
    "        df['DATE'] = date\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def filter_news(df, keywords):\n",
    "    # URL is column 57; we'll drop rows without URLs\n",
    "    df = df[df[57].notna()]\n",
    "    filtered = df[df[57].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "    return filtered\n",
    "\n",
    "def fetch_gkg_file(timestamp):\n",
    "    url = f\"http://data.gdeltproject.org/gkg/{timestamp}.gkg.csv.zip\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=20)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Not found: {timestamp}\")\n",
    "            return None\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        file_name = z.namelist()[0]\n",
    "        df = pd.read_csv(z.open(file_name), sep='\\t', header=None, encoding='utf-8', low_memory=False)\n",
    "        df['timestamp'] = timestamp\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {timestamp}: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_timestamps(start_date, end_date):\n",
    "    timestamps = []\n",
    "    current = start_date\n",
    "    while current <= end_date:\n",
    "        timestamps.append(current.strftime(\"%Y%m%d\"))\n",
    "        current += timedelta(days=1)\n",
    "    return timestamps\n",
    "\n",
    "def get_month_start_end(year, month):\n",
    "    from datetime import datetime, timedelta\n",
    "    start_date = datetime(year, month, 1)\n",
    "    next_month = start_date.replace(day=28) + timedelta(days=4)  # Ensures we move to the next month\n",
    "    end_date = next_month - timedelta(days=next_month.day)\n",
    "    return start_date, end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords = ['tesla', 'stock market', 'trump', 'congress', 'nasdaq']\n",
    "# all_filtered = []\n",
    "\n",
    "# start_date = datetime(2019, 1, 1)\n",
    "# end_date = datetime(2019, 1, 3)  # extend later\n",
    "\n",
    "# current_date = start_date\n",
    "# while current_date <= end_date:\n",
    "#     df = get_gdelt_export_for_date(current_date)\n",
    "#     if df is not None:\n",
    "#         df_filtered = filter_news(df, keywords)\n",
    "#         all_filtered.append(df_filtered)\n",
    "#     current_date += timedelta(days=1)\n",
    "\n",
    "# # Combine results\n",
    "# result_df = pd.concat(all_filtered, ignore_index=True)\n",
    "# result_df.to_csv(\"filtered_gdelt_news.csv\", index=False)\n",
    "# print(\"Saved filtered news to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_news_sentiment(years_vec, months_vec):\n",
    "    for yr in years_vec:\n",
    "        for month in months_vec:\n",
    "            # go from start of a month to end of a month\n",
    "            start, end = get_month_start_end(yr, month)\n",
    "            print(\"start date\", start, \"   end date\", end)\n",
    "            timestamps = generate_timestamps(start, end)\n",
    "\n",
    "            all_data = []\n",
    "\n",
    "            for ts in timestamps:\n",
    "                df = fetch_gkg_file(ts)\n",
    "                if df is not None:\n",
    "                    all_data.append(df)\n",
    "\n",
    "            # Combine and save\n",
    "            # full_df = pd.concat(all_data, ignore_index=True)\n",
    "            # full_df.to_csv(\"gdelt_gkg_data.csv\", index=False)\n",
    "\n",
    "            df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "            # df = pd.read_csv(\"gdelt_gkg_data.csv\", encoding='utf-8', low_memory=False)\n",
    "            selected_columns = [0,3,5,6,7]\n",
    "            # selected_columns = ['0','3','5','6','7']\n",
    "            df = df[selected_columns]\n",
    "            df.columns = ['DATE', 'THEMES', 'PERSONS', 'ORGANIZATIONS', 'TONE']\n",
    "            df = df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "            # Filter for TSLA stock\n",
    "            df = df[\n",
    "                df['ORGANIZATIONS'].fillna('').str.contains(\"Tesla|Tesla Inc\", case=False) |\n",
    "                df['PERSONS'].fillna('').str.contains(\"Elon Musk\", case=False) |\n",
    "                df['PERSONS'].fillna('').str.contains(\"Trump\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"Stock Market|Tech Stock Market|Tesla stock|Tesla shares|Tesla earnings|Tesla quarterly results\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"Tesla forecast|Tesla revenue|Tesla market dominance\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"EV|Electric vehicles|EV Market|vehicle deliveries|autopilot|full self-driving|FSD|Electricity\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"Tesla Model S|Tesla Model 3|Tesla Model X|Tesla Model Y|Tesla Cybertruck|Tesla Roadster\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"GDP|Unemployment|Employment\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"TSLA price target|TSLA stock split|Tesla market cap|TSLA earnings report|Tesla valuation\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"Tesla margins|Tesla guidance|TSLA analyst rating|short interest TSLA|Tesla institutional investors\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"Tesla energy|solar roof|Tesla Powerwall|Tesla AI|Dojo supercomputer|robotaxi|autonomous driving\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"Tesla software updates|neural net training|electric wall charger|battery charge stations\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"AI|Artificial Intelligence|artificial intelligence|production ramp|gigafactory|battery technology|regulatory approval\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"Tesla China|Tesla Berlin|Tesla Shanghai|EV tax credit|emissions regulation|trade tariffs|charging infrastructor\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"Tesla vs Ford|Tesla vs BYD|Tesla vs Rivian|Tesla vs Lucid|Tesla competition\", case=False) |\n",
    "                df['THEMES'].fillna('').str.contains(\"EV race|electric vehicle market share|Tesla rivals|Tesla disruption\", case=False)\n",
    "            ]\n",
    "\n",
    "            # Tone column: \"averageTone,positiveScore,negativeScore,numMentions,volatility,mediaBias\"\n",
    "            df['SentimentScore'] = df['TONE'].str.split(',').str[0].astype(float)\n",
    "\n",
    "            df['DATE'] = pd.to_datetime(df['DATE'], format=\"%Y%m%d\", errors='coerce')\n",
    "            df_daily_sentiment = df.groupby('DATE').agg({'SentimentScore': 'mean'}).reset_index()\n",
    "\n",
    "            # save sentiment score (provided daily) for each month to csv file\n",
    "            df_daily_sentiment.to_csv(f\"./gdelt_news_sentiment/daily_news_sentiment_{yr}_{month}.csv\", index=False)\n",
    "\n",
    "def get_news_sentiment_current_month(year, month):\n",
    "    # go from start of a month to end of a month\n",
    "    yr = year\n",
    "    start = datetime(yr, month, 1)\n",
    "    end   = datetime.today() - timedelta(days=1)\n",
    "    print(\"start date\", start, \"   end date\", end)\n",
    "    timestamps = generate_timestamps(start, end)\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for ts in timestamps:\n",
    "        df = fetch_gkg_file(ts)\n",
    "        if df is not None:\n",
    "            all_data.append(df)\n",
    "\n",
    "    # Combine and save\n",
    "    # full_df = pd.concat(all_data, ignore_index=True)\n",
    "    # full_df.to_csv(\"gdelt_gkg_data.csv\", index=False)\n",
    "\n",
    "    df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # df = pd.read_csv(\"gdelt_gkg_data.csv\", encoding='utf-8', low_memory=False)\n",
    "    selected_columns = [0,3,5,6,7]\n",
    "    # selected_columns = ['0','3','5','6','7']\n",
    "    df = df[selected_columns]\n",
    "    df.columns = ['DATE', 'THEMES', 'PERSONS', 'ORGANIZATIONS', 'TONE']\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "    # Filter for TSLA stock\n",
    "    df = df[\n",
    "        df['ORGANIZATIONS'].fillna('').str.contains(\"Tesla|Tesla Inc\", case=False) |\n",
    "        df['PERSONS'].fillna('').str.contains(\"Elon Musk|Trump\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"Stock Market|Tech Stock Market|Tesla stock|Tesla shares|Tesla earnings|Tesla quarterly results\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"Tesla forecast|Tesla revenue|Tesla market dominance\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"EV|Electric vehicles|EV Market|vehicle deliveries|autopilot|full self-driving|FSD|Electricity\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"Tesla Model S|Tesla Model 3|Tesla Model X|Tesla Model Y|Tesla Cybertruck|Tesla Roadster\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"GDP|Unemployment|Employment\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"TSLA price target|TSLA stock split|Tesla market cap|TSLA earnings report|Tesla valuation\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"Tesla margins|Tesla guidance|TSLA analyst rating|short interest TSLA|Tesla institutional investors\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"Tesla energy|solar roof|Tesla Powerwall|Tesla AI|Dojo supercomputer|robotaxi|autonomous driving\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"Tesla software updates|neural net training|electric wall charger|battery charge stations\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"AI|Artificial Intelligence|artificial intelligence|production ramp|gigafactory|battery technology|regulatory approval\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"Tesla China|Tesla Berlin|Tesla Shanghai|EV tax credit|emissions regulation|trade tariffs|charging infrastructor\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"Tesla vs Ford|Tesla vs BYD|Tesla vs Rivian|Tesla vs Lucid|Tesla competition\", case=False) |\n",
    "        df['THEMES'].fillna('').str.contains(\"EV race|electric vehicle market share|Tesla rivals|Tesla disruption\", case=False)\n",
    "    ]\n",
    "\n",
    "    # Tone column: \"averageTone,positiveScore,negativeScore,numMentions,volatility,mediaBias\"\n",
    "    df['SentimentScore'] = df['TONE'].str.split(',').str[0].astype(float)\n",
    "\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'], format=\"%Y%m%d\", errors='coerce')\n",
    "    df_daily_sentiment = df.groupby('DATE').agg({'SentimentScore': 'mean'}).reset_index()\n",
    "\n",
    "    # save sentiment score (provided daily) for each month to csv file\n",
    "    df_daily_sentiment.to_csv(f\"./gdelt_news_sentiment/daily_news_sentiment_{yr}_{month}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start date 2018-01-01 00:00:00    end date 2018-01-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "years_vec = [2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "months_vec= [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "get_historical_news_sentiment(years_vec, months_vec)\n",
    "# get_news_sentiment_current_month(2025, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = extract_historical_news_sentiment([], folder_path=\"gdelt_news_sentiment/Tesla_news_sentiment_old/\")\n",
    "df['SentimentScore_MA90'] = df['SentimentScore'].rolling(window=90).mean()\n",
    "df['SentimentScore_MA60'] = df['SentimentScore'].rolling(window=60).mean()\n",
    "df['SentimentScore_MA30'] = df['SentimentScore'].rolling(window=30).mean()\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(15,4))\n",
    "ax.plot(df[\"ds\"], df[\"SentimentScore\"],      c='orange',label='Dailay News Sentiment')\n",
    "ax.plot(df[\"ds\"], df[\"SentimentScore_MA90\"], c='red',   label='90-days Moving Average of News Sentiment')\n",
    "ax.plot(df[\"ds\"], df[\"SentimentScore_MA60\"], c='green', label='60-days Moving Average of News Sentiment')\n",
    "ax.plot(df[\"ds\"], df[\"SentimentScore_MA30\"], c='blue',  label='30-days Moving Average of News Sentiment')\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"SentimentScore\")\n",
    "ax.legend()\n",
    "\n",
    "df_2025 = df[df['ds']>='2025-01-01'].copy(deep=True)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(15,4))\n",
    "ax.plot(df_2025[\"ds\"], df_2025[\"SentimentScore\"],      c='orange',label='Dailay News Sentiment', marker='o')\n",
    "ax.plot(df_2025[\"ds\"], df_2025[\"SentimentScore_MA90\"], c='red',   label='90-days Moving Average of News Sentiment')\n",
    "ax.plot(df_2025[\"ds\"], df_2025[\"SentimentScore_MA60\"], c='green', label='60-days Moving Average of News Sentiment')\n",
    "ax.plot(df_2025[\"ds\"], df_2025[\"SentimentScore_MA30\"], c='blue',  label='30-days Moving Average of News Sentiment')\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"SentimentScore\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load FinBERT model (optimized for financial sentiment)\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Create pipeline\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = list(articles['title'].values)\n",
    "\n",
    "# Load FinBERT transformer model\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Run sentiment analysis\n",
    "results = sentiment_pipeline(headlines)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"headline\": headlines,\n",
    "    \"sentiment\": [r[\"label\"] for r in results],\n",
    "    \"confidence\": [r[\"score\"] for r in results]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"headline\": \"title\"}, inplace=True)\n",
    "# Merge sentiment scores with articles\n",
    "articles = articles.merge(df, on=\"title\", how=\"left\")\n",
    "articles['publishedAt'] = pd.to_datetime(articles['publishedAt']).dt.strftime('%Y-%m-%d')\n",
    "articles.rename(columns={'publishedAt': 'ds'}, inplace=True)\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment to numeric score\n",
    "sentiment_map = {\"positive\": 1, \"neutral\": 0, \"negative\": -1}\n",
    "articles['sentiment_score'] = articles['sentiment'].map(sentiment_map) * articles['confidence']\n",
    "# Daily average sentiment\n",
    "df_daily = articles.groupby('ds')['sentiment_score'].mean().reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
